{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69eb3bc6-03ae-429e-a8ff-b1566b86a825",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Patent Analysis\n",
    "\n",
    "* Airody Mohandas Pai\n",
    "* Chaitali Suhas Bagwe\n",
    "* Rakshit Bhat\n",
    "* Pranav Jayant Kulkarni\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7580b8a4-2bf8-4102-98ef-46a5a5f113d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Setting up external libraries \n",
    "\n",
    "1. <a href=\"https://pypi.org/project/yake/\" target=\"_blank\">YAKE</a> : Unsupervised Approach for Automatic Keyword Extraction using Text Features.\n",
    "2. <a href=\"https://pypi.org/project/german-nouns/\" target=\"_blank\">german-nouns</a> : A comma seperated list of ~100 thousand German nouns and their grammatical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb55bbd-7fe1-49a9-be69-5c06c3057546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To import external libraries, uncomment the lines below. \n",
    "# Reference for yake - https://github.com/LIAAD/yake\n",
    "\n",
    "\n",
    "import os\n",
    "os.system('pip install git+https://github.com/LIAAD/yake')\n",
    "os.system('pip install german-nouns')\n",
    "os.system('python -m spacy download de_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc4378-6847-44ae-b466-bf171dd0e12e",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "#### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d54bfa-4999-4b70-a693-f74795b42da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import yake\n",
    "\n",
    "from german_nouns.lookup import Nouns\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Beware of tensorflow error!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade895ed-b4d8-4e9c-b03c-1933e3eef6cd",
   "metadata": {},
   "source": [
    "***\n",
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d96722-653a-45e4-8e80-75b72480918a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0453b20b3b26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Phoenix_Contact_Makeathon_2022_Trainingsdatensatz.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chaitali bagwe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chaitali bagwe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\users\\chaitali bagwe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chaitali bagwe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \"\"\"\n\u001b[0;32m     23\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chaitali bagwe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd."
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('Phoenix_Contact_Makeathon_2022_Trainingsdatensatz.xlsx')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd08aa5-5771-4531-af5c-68c4e22dada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = pd.read_excel('Phoenix_Contact_Makeathon_2022_Testdatensatz.xlsx')\n",
    "testdataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a962e-aec9-47c2-ab38-3fbcb39c3c2e",
   "metadata": {},
   "source": [
    "***\n",
    "### Text Preprocessing\n",
    "\n",
    "#### 1) Setting up stop-words and stemmer\n",
    "Stop Words : Removing commonly used german stop words like *und*, *viel*, etc.\n",
    "\n",
    "Stemmer : Reducing the word to its word stem; *verbindung* -> *verbind*\n",
    "\n",
    "Part of Speech : Identify compound nouns; *batterieladegerat* -> *batterie + lade + gerat*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0891678-f95c-499f-aae4-2eea82772a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8e609-9994-4640-9fa8-43614271bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"german\")\n",
    "# Add custom stop words (frequently occuring but add no value)\n",
    "stop_words += ['non', 'referencing', 'claim', 'wobei', 'mindestens', 'erste', 'ersten', 'erstem', 'zweite', 'zumindestest', 'jeweils', 'zwei', 'wenigtens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8346243-44da-478a-9dbd-2c9117895604",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = Nouns()\n",
    "nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e0ccf-d0bf-44f6-8f15-35caf1e1fa0b",
   "metadata": {},
   "source": [
    "***\n",
    "#### Initializing YAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da28ac-05c8-498f-93c8-308114943a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ngram_size = 1\n",
    "deduplication_threshold = 0.9\n",
    "num_of_keywords = 30\n",
    "window_size = 1\n",
    "\n",
    "kw_extractor = yake.KeywordExtractor(n=max_ngram_size, dedupLim=deduplication_threshold, top=num_of_keywords, windowsSize=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c19f9e-0f44-4ed1-bd8b-2c4d67eb6234",
   "metadata": {},
   "source": [
    "#### 2) Cleaning the text\n",
    "Removing white spaces, html tags, numbers, special characters, punctuations and stop words and then finding stem of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbae78-3881-4ae7-93a3-38753c21a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove white spaces, html tags, numbers, special characters, punctuations\n",
    "\n",
    "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
    "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
    "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
    "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
    "\n",
    "    text = re.sub(RE_TAGS, \" \", text)\n",
    "    text = re.sub(RE_ASCII, \" \", text)\n",
    "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
    "    text = re.sub(RE_WSPACE, \" \", text)\n",
    "\n",
    "    word_tokens = word_tokenize(text)\n",
    "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
    "\n",
    "    # split compound nouns\n",
    "    doc = nlp(u''+' '.join(words_tokens_lower))\n",
    "    split_compound_nouns = \"\"\n",
    "\n",
    "    for word in doc:\n",
    "        words = nouns.parse_compound(word.orth_) if word.pos_ in ['NOUN', 'VERB', 'ADJ'] else [word.orth_,'']\n",
    "        split_compound_nouns += \" \".join(words) if len(words) > 1 else word.orth_\n",
    "        split_compound_nouns += \" \"\n",
    "\n",
    "    split_compound_nouns = split_compound_nouns.split(' ')\n",
    "\n",
    "    # perform stemming on each word\n",
    "    words_filtered = [\n",
    "        stemmer.stem(word) for word in split_compound_nouns if word not in stop_words\n",
    "    ]\n",
    "\n",
    "    text_clean = \" \".join(words_filtered)\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411cf82-6e83-4099-ab59-24cfad856e47",
   "metadata": {},
   "source": [
    "***\n",
    "#### Dataset Split\n",
    "Performing a 89:11 (3200:400) split for training and testing respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bae30-e716-408c-8c7b-ec31a9562fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into 3200:400 balenced entries\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[['Zusammenfassung', 'Unabhängige Patentansprüche', 'IPC-Hauptklasse']], dataset['IPC-Unterklasse'], test_size=0.1111, random_state=42, stratify=dataset['IPC-Unterklasse'])\n",
    "\n",
    "train_df = X_train.join(y_train)\n",
    "valdf = X_test.join(y_test)\n",
    "ext_testset = testdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc7507-5c28-49bf-95ea-b9e87bc3fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_text(pd_df):\n",
    "    pd_df['inputText'] = pd_df['Zusammenfassung'] + pd_df['Unabhängige Patentansprüche']\n",
    "    return pd_df[[\"inputText\", \"IPC-Hauptklasse\", \"IPC-Unterklasse\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c89cc-6ca3-4db1-817a-9fd3f7d9acb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_method_to_column(pd_df, col, meth):\n",
    "    return pd_df[col].apply(meth)\n",
    "    # return pd_df['inputText'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7c2b5-82cb-4346-8717-23a327ea39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(string):\n",
    "    keywords = kw_extractor.extract_keywords(string)\n",
    "    keywords = [x for (x,_) in keywords]\n",
    "    return \" \".join(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1446efd-6cc4-487c-b3f6-8f8a47d02d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_XGB_model(train_input, train_output, valinput):\n",
    "    clf = HistGradientBoostingClassifier()\n",
    "    clf.fit(train_input, train_output)  \n",
    "    pred = clf.predict(valinput)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae8206-c3fb-4429-abe9-bdca7d68734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(actual, predicted):\n",
    "    avg = 'weighted'\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(actual, predicted))\n",
    "    print(\"Precision:\",metrics.precision_score(actual, predicted, average=avg))\n",
    "    print(\"Recall:\",metrics.recall_score(actual, predicted, average=avg))\n",
    "    print(\"F1 score:\",metrics.f1_score(actual, predicted, average=avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954b08a-0680-4b17-8708-89bd9667dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sub_class_input(input_list, copy_list):\n",
    "    return_list = [[int(x[-1])] for x in input_list]\n",
    "    for i in range(len(return_list)):\n",
    "        return_list[i] += copy_list[i].copy()\n",
    " \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8765e-85e7-4975-b25c-241d75ba7e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mis_match_classes(main_preds, subclass_preds):\n",
    "    x = []\n",
    "    for i in range(len(subclass_preds)):\n",
    "        if (subclass_preds[i].find(main_preds[i]) < 0):\n",
    "            x += [(subclass_preds[i], main_preds[i])]\n",
    "        \n",
    "    if(len(x)):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1e137-2f50-4b75-9ce5-b8e3e504d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = generate_input_text(train_df)\n",
    "valdf = generate_input_text(valdf)\n",
    "test_df = generate_input_text(ext_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9437c6-4eff-4e1d-8355-5173a2ddf234",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cleaned_text'] = apply_method_to_column(train_df, 'inputText', clean_text)\n",
    "valdf['cleaned_text'] = apply_method_to_column(valdf, 'inputText', clean_text)\n",
    "test_df['cleaned_text'] = apply_method_to_column(test_df, 'inputText', clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f10c7-12a1-4be6-bbe9-ef6c53caa3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['yake_keywords'] = apply_method_to_column(train_df, 'cleaned_text', extract_keywords)\n",
    "# valdf['yake_keywords'] = apply_method_to_column(valdf, 'cleaned_text', extract_keywords)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9986d316-5875-43eb-978e-f5f81dba4b15",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "#### Feature extraction using TF-IDF\n",
    "TF-IDF measures how relvant a word is when compared with the entire document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1e815-0356-44c5-bd74-a8adc3bfbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizor = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd82dde9-79d3-4c7c-b427-9f63a4aa293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = tfidf_vectorizor.fit_transform(train_df['cleaned_text']).toarray().tolist()\n",
    "valinput = tfidf_vectorizor.transform(valdf['cleaned_text']).toarray().tolist()\n",
    "test_input = tfidf_vectorizor.transform(test_df['cleaned_text']).toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ebb15-959b-4737-a0e4-8dc63ba55d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = train_df['IPC-Hauptklasse'].tolist()\n",
    "valoutput =  valdf['IPC-Hauptklasse'].tolist()\n",
    "# test_output = train_df['IPC-Hauptklasse'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c82cb-074c-4f8e-9cd5-4424da7d3d03",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "#### Use Gradient Boosting Classifier to Identify Main Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f5819-39c3-45bd-8174-0e9f29a6e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_predictions = run_XGB_model(train_input, train_output, valinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91536b4f-ee50-40f0-bf15-0753cdcad5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics(valoutput, knn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc1cf0-0874-4e57-91b1-7d61d9264edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub_input = generate_sub_class_input(train_df['IPC-Hauptklasse'].tolist(), train_input)\n",
    "valsub_input = generate_sub_class_input(_predictions, valinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1443c28-33dd-4250-babd-c3f353abbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub_output = train_df['IPC-Unterklasse'].tolist()\n",
    "valsub_output = valdf['IPC-Unterklasse'].tolist()\n",
    "# test_sub_output = test_df['IPC-Unterklasse'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1abe2e-209d-46ca-870d-6e727c9a0676",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "#### Identify Sub Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aefe948-6bf8-4e5b-814f-8a418eba1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_subclass_predictions = run_XGB_model(train_sub_input, train_sub_output, valsub_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85017f09-a0ca-4d77-a85b-02816ef681ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics(valsub_output, knn_subclass_predictions)\n",
    "find_mis_match_classes(knn_predictions, knn_subclass_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc9265d-5eb2-4335-96e7-cd3211a13e8c",
   "metadata": {},
   "source": [
    "***\n",
    "#### Run on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e23aa-ea03-40c2-b3cb-997b56c09e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_main_predictions = run_XGB_model(train_input, train_output, test_input)\n",
    "test_sub_input = generate_sub_class_input(test_main_predictions, test_input)\n",
    "test_subclass_predictions = run_XGB_model(train_input, train_output, test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf341c3-8eec-4e01-b9e5-842f8c75ed23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "\n",
    "1 SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2336b25-ad59-4893-9508-591c7a640d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def run_model_svm(train_input, train_output, valinput):\n",
    "    model = svm.SVC(C=1.0, kernel='poly', degree=4)\n",
    "    model.fit(train_input, train_output)\n",
    "    return model.predict(valinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23d0f2-8a3c-438a-bd77-c057c575091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation data\n",
    "_predictions = run_model_svm(train_input, train_output, valinput)\n",
    "print_statistics(valoutput, _predictions)\n",
    "#train_sub_input = generate_sub_class_input(train_df['IPC-Hauptklasse'].tolist(), train_input)\n",
    "valsub_input = generate_sub_class_input(_predictions, valinput)\n",
    "_subclass_predictions = run_model_svm(train_sub_input, train_sub_output, valsub_input)\n",
    "print_statistics(valsub_output, _subclass_predictions)\n",
    "find_mis_match_classes(_predictions, _subclass_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d22dd-3f06-41b3-9a49-be90b8379f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "_predictions = run_model_svm(train_input, train_output, test_input)\n",
    "test_sub_input = generate_sub_class_input(_predictions, test_input)\n",
    "_subclass_predictions = run_model_svm(train_sub_input, train_sub_output, test_sub_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0299a25-fc20-46d1-8f6d-33b5efadea3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "\n",
    "2 Multinomial Naive Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f89956-da8d-44b6-b4ca-2b7f92f140bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def run_MNB_model(train_input, train_output, valinput):\n",
    "    _classifier = MultinomialNB()\n",
    "    _classifier.fit(train_input, train_output)\n",
    "    _predictions = _classifier.predict(valinput)\n",
    "    return _predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7e803-7184-4018-8544-73674723a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "_predictions = run_MNB_model(train_input, train_output, valinput)\n",
    "print_statistics(valoutput, _predictions)\n",
    "#train_sub_input = generate_sub_class_input(train_df['IPC-Hauptklasse'].tolist(), train_input)\n",
    "valsub_input = generate_sub_class_input(_predictions, valinput)\n",
    "_subclass_predictions = run_MNB_model(train_sub_input, train_sub_output, valsub_input)\n",
    "print_statistics(valsub_output, _subclass_predictions)\n",
    "find_mis_match_classes(_predictions, _subclass_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862a85a-919f-4bb1-9ab8-5f1de6da1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "_predictions = run_MNB_model(train_input, train_output, test_input)\n",
    "test_sub_input = generate_sub_class_input(_predictions, test_input)\n",
    "_subclass_predictions = run_MNB_model(train_sub_input, train_sub_output, test_sub_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fffc0a8-ad59-4a63-ac87-4a6a8a049617",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "\n",
    "3 Random Forest Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc912385-d4cc-4f10-a968-175d38923b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "def run_RF_model(train_input, train_output, valinput):\n",
    "    _classifier = RandomForestClassifier()\n",
    "    _classifier.fit(train_input, train_output)\n",
    "    _predictions = _classifier.predict(valinput)\n",
    "    return _predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304a0f3-735e-4243-a572-4ce6039468f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_predictions = run_RF_model(train_input, train_output, valinput)\n",
    "print_statistics(valoutput, _predictions)\n",
    "#train_sub_input = generate_sub_class_input(train_df['IPC-Hauptklasse'].tolist(), train_input)\n",
    "valsub_input = generate_sub_class_input(_predictions, valinput)\n",
    "_subclass_predictions = run_RF_model(train_sub_input, train_sub_output, valsub_input)\n",
    "print_statistics(valsub_output, _subclass_predictions)\n",
    "find_mis_match_classes(_predictions, _subclass_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4900b-c53f-4b91-a1de-bed63d85635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "rf_predictions = run_RF_model(train_input, train_output, test_input)\n",
    "test_sub_input = generate_sub_class_input(_predictions, test_input)\n",
    "rf_subclass_predictions = run_RF_model(train_sub_input, train_sub_output, test_sub_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4256f0d-9e63-436e-86b1-86b07f67e450",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "\n",
    "4 Gradient Boost Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc9250-c6ac-4957-9e91-29de4da8fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "def run_XGB_model(train_input, train_output, valinput):\n",
    "    # clf = XGBClassifier(max_depth=5, objective='multi:softmax', n_estimators=1000, num_classes=4)\n",
    "    # clf = GradientBoostingClassifier()\n",
    "    clf = HistGradientBoostingClassifier()\n",
    "    # clf = AdaBoostClassifier()\n",
    "    clf.fit(train_input, train_output)  \n",
    "    pred = clf.predict(valinput)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c608834-7760-4e13-89dc-e4fbe57c27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_predictions = run_XGB_model(train_input, train_output, valinput)\n",
    "print_statistics(valoutput, _predictions)\n",
    "#train_sub_input = generate_sub_class_input(train_df['IPC-Hauptklasse'].tolist(), train_input)\n",
    "valsub_input = generate_sub_class_input(_predictions, valinput)\n",
    "_subclass_predictions = run_XGB_model(train_sub_input, train_sub_output, valsub_input)\n",
    "print_statistics(valsub_output, _subclass_predictions)\n",
    "find_mis_match_classes(_predictions, _subclass_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d5353-40b6-4f10-9e89-8a734a2b8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "_predictions = run_XGB_model(train_input, train_output, test_input)\n",
    "test_sub_input = generate_sub_class_input(_predictions, test_input)\n",
    "_subclass_predictions = run_XGB_model(train_sub_input, train_sub_output, test_sub_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a3881-8e64-4790-a2f3-b3c9118455e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "\n",
    "5 Combination of two different classifiers for Main and Sub Class Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a488579-dfe1-4b02-9d95-fddec9638bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf mnb\n",
    "_predictions = run_RF_model(train_input, train_output, valinput)\n",
    "print_statistics(valoutput, _predictions)\n",
    "#train_sub_input = generate_sub_class_input(train_df['IPC-Hauptklasse'].tolist(), train_input)\n",
    "valsub_input = generate_sub_class_input(_predictions, valinput)\n",
    "\n",
    "_subclass_predictions = run_MNB_model(train_sub_input, train_sub_output, valsub_input)\n",
    "print_statistics(valsub_output, _subclass_predictions)\n",
    "find_mis_match_classes(_predictions, _subclass_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a36bcb0-263a-470d-9f22-c890e79f7f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "_predictions = run_RF_model(train_input, train_output, test_input)\n",
    "test_sub_input = generate_sub_class_input(_predictions, test_input)\n",
    "_subclass_predictions = run_MNB_model(train_sub_input, train_sub_output, test_sub_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a47581-a795-4391-90af-020544001f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn rf\n",
    "_predictions = run_knn_clf(train_input, train_output, valinput)\n",
    "print_statistics(valoutput, _predictions)\n",
    "#train_sub_input = generate_sub_class_input(train_df['IPC-Hauptklasse'].tolist(), train_input)\n",
    "valsub_input = generate_sub_class_input(_predictions, valinput)\n",
    "\n",
    "_subclass_predictions = run_RF_model(train_sub_input, train_sub_output, valsub_input)\n",
    "print_statistics(valsub_output, _subclass_predictions)\n",
    "find_mis_match_classes(_predictions, _subclass_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd33c0-6937-4f29-8b33-92702d91bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn mnb\n",
    "_predictions = run_knn_clf(train_input, train_output, valinput)\n",
    "print_statistics(valoutput, _predictions)\n",
    "#train_sub_input = generate_sub_class_input(train_df['IPC-Hauptklasse'].tolist(), train_input)\n",
    "valsub_input = generate_sub_class_input(_predictions, valinput)\n",
    "\n",
    "_subclass_predictions = run_MNB_model(train_sub_input, train_sub_output, valsub_input)\n",
    "print_statistics(valsub_output, _subclass_predictions)\n",
    "find_mis_match_classes(_predictions, _subclass_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f845674-7f3e-4237-938c-8dd6e2ec1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf knn\n",
    "_predictions = run_RF_model(train_input, train_output, valinput)\n",
    "print_statistics(valoutput, _predictions)\n",
    "#train_sub_input = generate_sub_class_input(train_df['IPC-Hauptklasse'].tolist(), train_input)\n",
    "valsub_input = generate_sub_class_input(_predictions, valinput)\n",
    "\n",
    "_subclass_predictions = run_knn_clf(train_sub_input, train_sub_output, valsub_input)\n",
    "print_statistics(valsub_output, _subclass_predictions)\n",
    "find_mis_match_classes(_predictions, _subclass_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a508996-58af-41fe-bb66-03fe8792b854",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "\n",
    "Data Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109f920-1893-414c-87ec-4662846f3576",
   "metadata": {},
   "outputs": [],
   "source": [
    "valmain_act = dict(valdf['IPC-Hauptklasse'].value_counts())\n",
    "valsub_act = dict(valdf['IPC-Unterklasse'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e52055-caa9-40bd-a6ef-3e855c7586d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pred = {}\n",
    "for x in knn_predictions:\n",
    "    if x in main_pred:\n",
    "        main_pred[x] += 1\n",
    "    else:\n",
    "        main_pred[x] = 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be444f8-0370-4d36-ae32-88dc5860379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_pred = {}\n",
    "for x in knn_subclass_predictions:\n",
    "    if x in sub_pred:\n",
    "        sub_pred[x] += 1\n",
    "    else:\n",
    "        sub_pred[x] = 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3970652-d76d-4bcb-a51a-7e2c19962ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dict = []\n",
    "list_of_dict.append(valmain_act)\n",
    "list_of_dict.append(main_pred)\n",
    "list_of_dict.append(valsub_act)\n",
    "list_of_dict.append(sub_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ffc78-e3bd-4867-adcf-6d07cbb9a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in list_of_dict:\n",
    "    #explode = (0, 0.0, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(list(l.values()), labels=list(l.keys()), autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376b80e-84ca-472a-8d23-ac93c2825d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_params = { 'n_neighbors' : [5,7,9,11,13,15,17],\n",
    "#                'weights' : ['uniform','distance'],\n",
    "#                'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "# gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "\n",
    "# g_res = gs.fit(train_input, train_output)\n",
    "# g_res.best_score_\n",
    "# g_res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8c3cc-5d66-48f0-b346-611eb4b9170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_params = { 'n_neighbors' : [5,7,9,11,13,15,17],\n",
    "#                'weights' : ['uniform','distance'],\n",
    "#                'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "# gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "\n",
    "# g_res = gs.fit(train_input, train_output)\n",
    "# g_res.best_score_\n",
    "# g_res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95a523-9354-41c1-b0cd-d385a893eb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
